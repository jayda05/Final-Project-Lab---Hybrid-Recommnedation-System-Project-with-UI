{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtUxe-GDJW_4",
        "outputId": "4da8b836-9fa6-4fdd-f506-43d76b72d73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "#5. Evaluation Report\n",
        "!pip install scikit-surprise\n",
        "from surprise import accuracy\n",
        "\n",
        "def evaluate_model(predictions):\n",
        "    \"\"\"Calculate evaluation metrics\"\"\"\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "    mae = accuracy.mae(predictions)\n",
        "    return {'RMSE': rmse, 'MAE': mae}\n",
        "\n",
        "def compute_top_n_metrics(testset, user_id, top_n=10):\n",
        "    \"\"\"Calculate precision/recall metrics\"\"\"\n",
        "    test_df = pd.DataFrame([(pred.uid, pred.iid, pred.r_ui, pred.est) for pred in testset],\n",
        "                         columns=['userId', 'movieId', 'actual', 'predicted'])\n",
        "    user_df = test_df[test_df['userId'] == user_id]\n",
        "\n",
        "    if user_df.empty:\n",
        "        return None\n",
        "\n",
        "    actual_liked = user_df[user_df['actual'] >= 4]['movieId'].values\n",
        "    predicted_top = user_df.sort_values('predicted', ascending=False)['movieId'].head(top_n).values\n",
        "\n",
        "    true_positives = len(np.intersect1d(actual_liked, predicted_top))\n",
        "    precision = true_positives / top_n if top_n else 0\n",
        "    recall = true_positives / len(actual_liked) if len(actual_liked) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'actual_count': len(actual_liked),\n",
        "        'recommended_count': len(predicted_top)\n",
        "    }"
      ]
    }
  ]
}